# Desafio TÃ©cnico - Ligia (Liga de IA da UFPE)

## Trilha: Machine Learning - DetecÃ§Ã£o de Fraudes

**Autor:** [Seu Nome Completo]
**CompetiÃ§Ã£o Kaggle:** [Nome ou Link da CompetiÃ§Ã£o]

---

## ğŸ“Œ VisÃ£o Geral do Projeto

Este repositÃ³rio contÃ©m a soluÃ§Ã£o desenvolvida para a etapa tÃ©cnica do processo seletivo da Ligia. O objetivo Ã© desenvolver um modelo de InteligÃªncia Artificial capaz de detectar transaÃ§Ãµes financeiras fraudulentas.

O problema Ã© caracterizado como uma tarefa de **classificaÃ§Ã£o binÃ¡ria em dados desbalanceados**, onde a mÃ©trica principal de avaliaÃ§Ã£o Ã© a **ROC-AUC**.

### ğŸ¯ Objetivos

1. Realizar AnÃ¡lise ExploratÃ³ria de Dados (EDA) para identificar padrÃµes de fraude.
2. Implementar estratÃ©gias para tratamento de classes desbalanceadas.
3. Treinar e validar modelos de Machine Learning (foco em Gradient Boosting).
4. Garantir a interpretabilidade do modelo (XAI) para justificar as decisÃµes.
5. Gerar submissÃ£o formatada para o Kaggle.

---

## ğŸ“‚ Estrutura do RepositÃ³rio

A organizaÃ§Ã£o do cÃ³digo segue uma lÃ³gica de separaÃ§Ã£o entre exploraÃ§Ã£o, processamento e modelagem:

```text
â”œâ”€â”€ data/                           # (Ignorado no Git) Pasta para datasets raw/processed
â”‚
â”œâ”€â”€ notebooks/                      # Jupyter Notebooks para anÃ¡lise e experimentos
â”‚   â”œâ”€â”€ 01_eda_analise.ipynb        # AnÃ¡lise exploratÃ³ria e visualizaÃ§Ãµes
â”‚   â””â”€â”€ 02_modelagem_testes.ipynb   # Testes de algoritmos e validaÃ§Ã£o cruzada
â”‚
â”œâ”€â”€ src/                            # Scripts Python para execuÃ§Ã£o reprodutÃ­vel
â”‚   â”œâ”€â”€ preprocessing.py            # Pipelines de tratamento de dados
â”‚   â”œâ”€â”€ train.py                    # Script principal de treinamento
â”‚   â””â”€â”€ inference.py                # Script para gerar o arquivo de submissÃ£o
â”‚
â”œâ”€â”€ models/                         # Artefatos serializados (modelos salvos)
â”‚   â”œâ”€â”€ model.joblib                # Modelo final treinado
â”‚   â””â”€â”€ scaler.pkl                  # Scaler ajustado (se aplicÃ¡vel)
â”‚
â”œâ”€â”€ submission/                     # Arquivos de saÃ­da
â”‚   â””â”€â”€ submission.csv              # Arquivo pronto para o Kaggle
â”‚
â”œâ”€â”€ requirements.txt                # Lista de dependÃªncias do projeto
â”‚
â””â”€â”€ README.md                       # DocumentaÃ§Ã£o do projeto
```

## ğŸš€ Como Executar o Projeto

Para garantir a reprodutibilidade da soluÃ§Ã£o, siga os passos abaixo:

### 1. InstalaÃ§Ã£o das DependÃªncias

Recomenda-se a criaÃ§Ã£o de um ambiente virtual (venv ou conda).

```bash
# Clone o repositÃ³rio
git clone [Link do Seu RepositÃ³rio]
cd [Nome da Pasta]

# Instale os pacotes necessÃ¡rios
pip install -r requirements.txt

### 2. Reproduzir o Treinamento
Para treinar o modelo do zero e salvar os artefatos na pasta `models/`:
```

```bash
python src/train.py

### 3. Gerar SubmissÃ£o (InferÃªncia)
Para gerar o arquivo `.csv` com as probabilidades para o Kaggle:
```

```bash
python src/inference.py
```

## ğŸ§  Abordagem TÃ©cnica e Metodologia

### PrÃ©-processamento

* **Limpeza:** Tratamento de valores nulos utilizando [ex: inputaÃ§Ã£o pela mediana].
* **Feature Engineering:** CriaÃ§Ã£o de novas variÃ¡veis baseadas em [ex: agregaÃ§Ã£o de tempo ou valor].
* **NormalizaÃ§Ã£o:** AplicaÃ§Ã£o de [ex: StandardScaler ou MinMaxScaler] (se aplicÃ¡vel).

### EstratÃ©gia de Desbalanceamento

Dada a baixa prevalÃªncia de fraudes, foi utilizada a tÃ©cnica [Escolha uma: SMOTE / Class Weights / Undersampling] para equilibrar a importÃ¢ncia das classes durante o treinamento.

### Modelagem

* **Baseline:** Foi utilizada uma RegressÃ£o LogÃ­stica simples como linha de base.
* **Modelo Final:** O algoritmo escolhido foi o **[ex: XGBoost / LightGBM]**.
* **ValidaÃ§Ã£o:** Stratified K-Fold Cross-Validation (5 dobras) para garantir robustez nas mÃ©tricas.

### Interpretabilidade (XAI)

Para cumprir o requisito de explicabilidade "White Box", foi utilizada a biblioteca **SHAP (SHapley Additive exPlanations)**. As anÃ¡lises de importÃ¢ncia das features podem ser visualizadas no notebook `notebooks/02_modelagem_testes.ipynb`.

## ğŸ“Š Resultados Preliminares

| Modelo | ROC-AUC (ValidaÃ§Ã£o) |
| :--- | :--- |
| Baseline (RegressÃ£o LogÃ­stica) | 0.XX |
| **Modelo Proposto ([Nome])** | **0.XX** |

---

## ğŸ›  Tecnologias Utilizadas

* Python 3.8+
* Pandas & NumPy
* Scikit-Learn
* [XGBoost / LightGBM / CatBoost]
* SHAP (Interpretabilidade)
* Matplotlib & Seaborn